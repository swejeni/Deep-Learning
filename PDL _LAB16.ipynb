{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SWETHA JENIFER S\n",
    "#### 225229142"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDL Lab16. Design of LSTM and GRU RNN for classification of IMDB reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, GRU \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's been about 14 years since Sharon Stone aw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>someone needed to make a car payment... this i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Guidelines state that a comment must conta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This movie is a muddled mish-mash of clichés f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Before Stan Laurel became the smaller half of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  It's been about 14 years since Sharon Stone aw...      0\n",
       "1  someone needed to make a car payment... this i...      0\n",
       "2  The Guidelines state that a comment must conta...      0\n",
       "3  This movie is a muddled mish-mash of clichés f...      0\n",
       "4  Before Stan Laurel became the smaller half of ...      0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('imdb.csv', encoding='latin1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sweth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "english_stops = set(stopwords.words('english'))\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_sto = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews\n",
      "0     [', 14, -, ', ., ,, ,, ', ., \", 2\", -, \", \", ....\n",
      "1     [..., ..., ', ..., ..., ..., ., ?, ., ., $5.99...\n",
      "2                                       [., ., ,, ., .]\n",
      "3     [-, é, ., ,, ,, ., ', ., ,, (, ,, ,, ).<, /><,...\n",
      "4     [-, ,, ,, ., ,, ', (, ), .<, /><, />, ', ,, ',...\n",
      "                            ...                        \n",
      "81    [., ', ..., ., ', -, -, -, ., (, ).<, /><, />,...\n",
      "82    [,, 6, .<, /><, />, ', 2, ,, 11, 2001., ,, (, ...\n",
      "83    [., -, -, ., ,, ,, ., ., ., -, -, ,, ', ,, ,, ...\n",
      "84    [., ,, ,, ', ., ,, \", \", ., ., ', ., ,, ', /, ...\n",
      "85    [,, ', \", /, \", ,, ., (, ', ), \", \"., (, ), .,...\n",
      "Name: text, Length: 86, dtype: object \n",
      "\n",
      "Sentiment\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "     ..\n",
      "81    0\n",
      "82    1\n",
      "83    1\n",
      "84    0\n",
      "85    0\n",
      "Name: label, Length: 86, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def load_dataset():\n",
    "    df = pd.read_csv('imdb.csv', encoding='latin1')\n",
    "    x_data = df['text']\n",
    "    y_data = df['label']\n",
    "    x_data = x_data.replace({'[’A-Za-z]' : ' '}, regex = True)\n",
    "    x_data = x_data.apply(lambda review: [w for w in review.split() if w not in english_sto]) \n",
    "    x_data = x_data.apply(lambda review: [w.lower() for w in review])\n",
    "    y_data = y_data.replace('positive', 1) \n",
    "    y_data = y_data.replace('negative', 0)\n",
    "    return x_data, y_data \n",
    "x_data, y_data = load_dataset() \n",
    "print('Reviews')\n",
    "print(x_data, '\\n')\n",
    "print('Sentiment')\n",
    "print(y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set\n",
      "1     [..., ..., ', ..., ..., ..., ., ?, ., ., $5.99...\n",
      "14    [', ', (, 10, ), ., ', ', ,, ', .<, /><, />', ...\n",
      "6     [(, é), ,, ., ,, -, ., (, é, ),, ,, ., ,, ', (...\n",
      "80    [,, ., ', -, .<, /><, />, ', ., ,, .<, /><, />...\n",
      "46    [90', ', '., ., ., ', ., ., ., ., ,, ,, ', ., ...\n",
      "34    [..., ..., ', ., ., -, ', ..., ..., ', ., ', -...\n",
      "32    [., ,, ., ,, ,, .<, /><, />, ,, ,, .<, /><, />...\n",
      "12    [,, <, /><, />, ., 9, ,, <, /><, />, ,, 4, <, ...\n",
      "33    [-, ,, \", \", -, \", -, \", ., ', ,, ,, -, ', ,, ...\n",
      "52    [,, --, --, ., ,, ., ,, --, ', --, ,, 11, 09, ...\n",
      "78    [-8,, (, ), ., 2, (, ), .<, /><, />, -, ?, ,, ...\n",
      "54                                [,, ', ., 4, ., ,, .]\n",
      "45                                         [., ., ., .]\n",
      "68    [1937, ,, ,, ,, 20, ., \", \", (\", \", \", \"), ., ...\n",
      "10                             [', ,, ., ,, ., ,, ,, .]\n",
      "41    [:, <, /><, />1), (, ), ,, ., ,, (, \", \"), ,, ...\n",
      "8     [., ,, ., ,, ..., ,, ., ., ', ..., ., ., ,, (,...\n",
      "7     [\", \", \", \", ., ., ., ', ?, \\, ., ., ,, ', ., ...\n",
      "84    [., ,, ,, ', ., ,, \", \", ., ., ', ., ,, ', /, ...\n",
      "61    [;, ,, ..., ,.., ', ,, ,, \", \", ,, ,, ..., ., ...\n",
      "43    [,, ., ', .<, /><, />, ,, (, ), ,, ., ., ?, ',...\n",
      "48              [,, ,, ., ., ., ', ,, ., ., ., ,, ., .]\n",
      "60    [\", \"-, ,, ., ,, ,, ., ,, ,, ,, ,, ,, .<, /><,...\n",
      "70    [1993,, :, ,, -, -, ,, -, -, ,, ., :, ., ,, -,...\n",
      "19           [,, ., ., ,, ., ., ., ., ., ,, ,, ,, ,, .]\n",
      "25    [', ., ', ., ., ,, ,, ., ', ., ', ,, ., ., ,, ...\n",
      "37    [\", \", -, ., ., ,, (, ), ,, ,, .<, /><, />, ,,...\n",
      "75    [., .<, /><, />, ,, ., ,, ,, .<, /><, />, ., ?...\n",
      "24    [,, ,, ,, ., ', ., (, )., ., ., ,, -, ., ', ',...\n",
      "76    [5, 6, ., .<, /><, />, ., ', !!!, ., \", \"., !,...\n",
      "16    [', ,, ., \", \",, \", \", ,, ,, ., \", \", ,, ., ,,...\n",
      "49                 [., ,, ,, ., ,, ., ,, ,, ., ,, ., .]\n",
      "21    [,, ,, ., (, ),, \", \", ,, (, ),, ,, ,, ,, ,, ....\n",
      "13    [,, ', 1933, ., -, ;, ', ,, .<, /><, />, ,, ',...\n",
      "69    [,, ,, \", \", ;, -, ?, ', \", \", ', ,, ., ,, ', ...\n",
      "26    [,, ., ,, ', ., ,, ,, ,, ,, (, ), ., ,, .<, />...\n",
      "22    [,, ,, -, ,, /, (, \", \"--, )., ,, (, )., ,, ,,...\n",
      "30    [,, 14-, ;, ,, ', ', ,, ,, ,, ,, .<, /><, />, ...\n",
      "57    [,, ,, ,, ., ,, ', ,, ,, ,, .<, /><, />, :, [1...\n",
      "71    [\", \", -, -, ., .<, /><, />, \", \", ,, ,, ,, \",...\n",
      "67    [', !!, !, ., ', ,, ., ., -80, ., ., ., ,, 100...\n",
      "39    [(, ), ., ,, ', ., ', ,, ', ,, ., ., ,, ', ,, ...\n",
      "77    [,, ', -, ', ., ,, ,, ,, ', ', ., ., ,, ', ', ...\n",
      "3     [-, é, ., ,, ,, ., ', ., ,, (, ,, ,, ).<, /><,...\n",
      "0     [', 14, -, ', ., ,, ,, ', ., \", 2\", -, \", \", ....\n",
      "74    [,, ., ,, ,, ,, ', ., ., ,, --, ', ., ., -, -,...\n",
      "4     [-, ,, ,, ., ,, ', (, ), .<, /><, />, ', ,, ',...\n",
      "65    [,, ,, 17, 4.8, ,, ., ', ,, ', .<, /><, />, ,,...\n",
      "38    [., ,, ,, ., ', ,, ', !!, ;), ', (, ), .<, /><...\n",
      "64    [,, ?, ', ?, ', ?, ., ', ', ..., ?, ?, ?, ?, -...\n",
      "59    [,, ,, .<, /><, />, ,, ., ,, ,, ., ,, ., ', .,...\n",
      "Name: text, dtype: object \n",
      "\n",
      "2                                       [., ., ,, ., .]\n",
      "11    [', ', -, ', ., ', ., ', ',, ', ', .<, /><, />...\n",
      "50    [,, ,, ', ,, \", ,, .\", ', ', ., ,, ', ,, ', ,,...\n",
      "63    [., ,, 5-7, ., ', ,, .<, /><, />, ., ,, ,, ., ...\n",
      "15    [-, ,, \", \", 100., ,, ,, (, ),, ., -, ', ,, .,...\n",
      "53    [,, !, ., ,, ..., ', ...<, /><, />, ;, ., ,, '...\n",
      "35    [-, -, ,, ;, ,, ', ', ,, ., ,, ,, ,, ,, ', ., ...\n",
      "17    [,, ,, ,, ., .<, /><, />, -, ..., ,, ., -, ,, ...\n",
      "40    [,, ,, ., ,, .<, /><, />, ,, ,, ', ?, ,, ,, ,,...\n",
      "47    [,, ,, 10, ', ', ,, ', ,, (, ,, ), ., ', ?<, /...\n",
      "58               [., ??,, ., ., ,, 1, ', 1:42, -, ., .]\n",
      "44                          [,, ., ., ?, ., ., ., ., .]\n",
      "66    [', 1959, 1962., 1959;, ,, .<, /><, />, ,, ,, ...\n",
      "85    [,, ', \", /, \", ,, ., (, ', ), \", \"., (, ), .,...\n",
      "5     [', !, <, /><, />, ', ,, ., ,, !, ,, .<, /><, ...\n",
      "81    [., ', ..., ., ', -, -, -, ., (, ).<, /><, />,...\n",
      "27    [\", \", .., ., ', ., ', ', !!, ..<, /><, />, 10...\n",
      "29             [,, -, -, ., ., (, ), ', ., ., ., 4/10.]\n",
      "83    [., -, -, ., ,, ,, ., ., ., -, -, ,, ', ,, ,, ...\n",
      "73    [,, ,, !, ', ,, ., !!, ,, ', ,, 8, ,, ,, ., ,,...\n",
      "55    [,, ', ,, ?, ', ', ,, ?, ?, ,, ', ,, ', ,, ?<,...\n",
      "72    [-, ., ,, ,, ', ., ..., ?, 1991., --, !, ., ,,...\n",
      "20    [(, ), 80', ,, ., ,, ., ,, ., ,, ,, ., \", -, \"...\n",
      "36    [4, ., ,, ', ., ,, ., ', ?, ', ,, ., 4, (, ,, ...\n",
      "31                       [., ., ., ,, ,, ., ,, ., ', .]\n",
      "28    [', ,, ,, ', \", \"., ,, .<, /><, />, ', ,, ., ....\n",
      "82    [,, 6, .<, /><, />, ', 2, ,, 11, 2001., ,, (, ...\n",
      "62    [,, ,, (, ), ., (, ),, (, )., ,, (, ), ,, ,, ....\n",
      "51                             [., ,, ., ,, ,, ., ., .]\n",
      "23    [', ', -, -, ,, ', !, ,, ,, -, ., ,, ', ', ., ...\n",
      "79                 [,, ., ., ., ., ., ,, ,, ., ', ', .]\n",
      "56    [., ', ., ., 2, ', ., ., ,, ,, 2:, ,, ., ,, ',...\n",
      "9     [1.5, ?, ?, ?<, /><, />, ', ., ., ,, ,, ., ,, ...\n",
      "42     [,, ., ., ., ', ., \", \", ., ,, ., ., ., -, ., .]\n",
      "18    [,, ,, ,, ..., ., ., ,, ,, ., ., .<, /><, />, ...\n",
      "Name: text, dtype: object \n",
      "\n",
      "Test Set\n",
      "1     0\n",
      "14    1\n",
      "6     1\n",
      "80    1\n",
      "46    1\n",
      "34    1\n",
      "32    1\n",
      "12    0\n",
      "33    0\n",
      "52    1\n",
      "78    0\n",
      "54    0\n",
      "45    1\n",
      "68    1\n",
      "10    1\n",
      "41    0\n",
      "8     1\n",
      "7     0\n",
      "84    0\n",
      "61    0\n",
      "43    0\n",
      "48    1\n",
      "60    1\n",
      "70    1\n",
      "19    1\n",
      "25    0\n",
      "37    1\n",
      "75    0\n",
      "24    0\n",
      "76    1\n",
      "16    1\n",
      "49    1\n",
      "21    0\n",
      "13    1\n",
      "69    0\n",
      "26    1\n",
      "22    1\n",
      "30    0\n",
      "57    0\n",
      "71    0\n",
      "67    1\n",
      "39    1\n",
      "77    0\n",
      "3     0\n",
      "0     0\n",
      "74    1\n",
      "4     0\n",
      "65    0\n",
      "38    0\n",
      "64    0\n",
      "59    0\n",
      "Name: label, dtype: int64 \n",
      "\n",
      "2     0\n",
      "11    0\n",
      "50    1\n",
      "63    1\n",
      "15    1\n",
      "53    0\n",
      "35    1\n",
      "17    0\n",
      "40    0\n",
      "47    1\n",
      "58    0\n",
      "44    1\n",
      "66    1\n",
      "85    0\n",
      "5     1\n",
      "81    0\n",
      "27    0\n",
      "29    0\n",
      "83    1\n",
      "73    0\n",
      "55    0\n",
      "72    0\n",
      "20    1\n",
      "36    0\n",
      "31    0\n",
      "28    1\n",
      "82    1\n",
      "62    0\n",
      "51    0\n",
      "23    0\n",
      "79    1\n",
      "56    1\n",
      "9     0\n",
      "42    0\n",
      "18    0\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.4)\n",
    "print('Train Set') \n",
    "print(x_train, '\\n') \n",
    "print(x_test, '\\n') \n",
    "print('Test Set') \n",
    "print(y_train, '\\n') \n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_length(): \n",
    "    review_length = []\n",
    "    for review in x_train: \n",
    "        review_length.append(len(review))\n",
    "    return int(np.ceil(np.mean(review_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Encoded X Train\n",
      " [[ 10  10   3 ...   0   0   0]\n",
      " [  3   3   9 ...   2   1   8]\n",
      " [  9  58   1 ...  23   4  37]\n",
      " ...\n",
      " [  2   1   1 ...   5   2   2]\n",
      " [  1  11   3 ...   3 144   3]\n",
      " [  1   1   8 ...   0   0   0]] \n",
      "\n",
      " Encoded X Test\n",
      " [[ 2  2  1 ...  0  0  0]\n",
      " [ 3  3  5 ...  3  2  1]\n",
      " [ 1  1  3 ...  2  3 11]\n",
      " ...\n",
      " [11 11  6 ...  0  0  0]\n",
      " [ 1  2  2 ...  0  0  0]\n",
      " [ 1  1  1 ...  8  6  7]] \n",
      "\n",
      "Maximum review length:  51\n"
     ]
    }
   ],
   "source": [
    "token   =   Tokenizer(lower=False)\n",
    "token.fit_on_texts(x_train)\n",
    "x_train = token.texts_to_sequences(x_train)\n",
    "x_test = token.texts_to_sequences(x_test) \n",
    "max_length = get_max_length()\n",
    "x_train=pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post') \n",
    "x_test=pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "total_words = len(token.word_index) + 1\n",
    "\n",
    "print(' Encoded X Train\\n', x_train, '\\n') \n",
    "print(' Encoded X Test\\n', x_test, '\\n') \n",
    "print('Maximum review length: ', max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 156, 32)           4640      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                24832     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31585 (123.38 KB)\n",
      "Trainable params: 31585 (123.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "EMBED_DIM = 32\n",
    "LSTM_OUT = 64\n",
    "\n",
    "# Assuming x_data is a list of lists, where each inner list contains words\n",
    "sentences = [' '.join(sentence) for sentence in x_data]\n",
    "\n",
    "# Calculate the maximum sequence length\n",
    "max_sequence_length = max(len(sentence.split()) for sentence in sentences)\n",
    "\n",
    "# Set your_input_length to the maximum sequence length\n",
    "your_input_length = max_sequence_length\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, EMBED_DIM, input_length=your_input_length))\n",
    "model.add(LSTM(LSTM_OUT))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6951 - accuracy: 0.4510\n",
      "Epoch 1: accuracy improved from -inf to 0.45098, saving model to models\\LSTM.h5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6951 - accuracy: 0.4510\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.5294\n",
      "Epoch 2: accuracy improved from 0.45098 to 0.52941, saving model to models\\LSTM.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweth\\Downloads\\nlp\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6937 - accuracy: 0.5294\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6925 - accuracy: 0.5294\n",
      "Epoch 3: accuracy did not improve from 0.52941\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6925 - accuracy: 0.5294\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6918 - accuracy: 0.6471\n",
      "Epoch 4: accuracy improved from 0.52941 to 0.64706, saving model to models\\LSTM.h5\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.6918 - accuracy: 0.6471\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6910 - accuracy: 0.6275\n",
      "Epoch 5: accuracy did not improve from 0.64706\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6910 - accuracy: 0.6275\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6901 - accuracy: 0.6275\n",
      "Epoch 6: accuracy did not improve from 0.64706\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6901 - accuracy: 0.6275\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6892 - accuracy: 0.6078\n",
      "Epoch 7: accuracy did not improve from 0.64706\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6892 - accuracy: 0.6078\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6883 - accuracy: 0.6078\n",
      "Epoch 8: accuracy did not improve from 0.64706\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6883 - accuracy: 0.6078\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6872 - accuracy: 0.6078\n",
      "Epoch 9: accuracy did not improve from 0.64706\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6872 - accuracy: 0.6078\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6862 - accuracy: 0.6275\n",
      "Epoch 10: accuracy did not improve from 0.64706\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6862 - accuracy: 0.6275\n",
      "2/2 [==============================] - 1s 9ms/step - loss: 0.6962 - accuracy: 0.4857\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 51, 32)            4640      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14049 (54.88 KB)\n",
      "Trainable params: 14049 (54.88 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "modell = Sequential()\n",
    "modell.add(Embedding(total_words, 32, input_length=max_length)) \n",
    "modell.add(LSTM(32))\n",
    "modell.add(Dense(32, activation='relu')) \n",
    "modell.add(Dense(1, activation='sigmoid'))\n",
    "modell.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy']) \n",
    "modell.fit(x_train, y_train, batch_size = 128, epochs = 10, callbacks=[checkpoint]) \n",
    "modell.evaluate(x_test, y_test)\n",
    "print(modell.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6931 - accuracy: 0.5098\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6911 - accuracy: 0.5882\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6897 - accuracy: 0.5686\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6885 - accuracy: 0.5882\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6872 - accuracy: 0.6275\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6857 - accuracy: 0.6471\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6841 - accuracy: 0.6471\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6822 - accuracy: 0.6275\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6799 - accuracy: 0.6275\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6773 - accuracy: 0.6275\n",
      "2/2 [==============================] - 1s 13ms/step - loss: 0.7042 - accuracy: 0.4857\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 51, 32)            4640      \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 64)                16640     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23393 (91.38 KB)\n",
      "Trainable params: 23393 (91.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(total_words, 32, input_length=max_length)) \n",
    "model2.add(Bidirectional(LSTM(32)))\n",
    "model2.add(Dense(32, activation='relu')) \n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy']) \n",
    "model2.fit(x_train, y_train, batch_size = 128, epochs = 10)\n",
    "model2.evaluate(x_test, y_test) \n",
    "print(model2.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7042 - accuracy: 0.4857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7042022347450256, 0.48571428656578064]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "t = Tokenizer()\n",
    "# De fin i ng 4 doc men t L i sts\n",
    "fit_text = ['Machine Learning Knowledge', 'Machine Learning',\n",
    "'Deep Learning',\n",
    "'Artificial Intelligence'] \n",
    "t.fit_on_texts(fit_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.preprocessing.text.Tokenizer at 0x1532259dca0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
